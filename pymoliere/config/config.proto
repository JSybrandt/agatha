syntax = "proto2";
package pymoliere;


// This is used to specify the remote location of pubmed articles.
// Defaults to the most recent baseline.
message FtpSource {
  optional string address = 1 [default="ftp.ncbi.nlm.nih.gov"];
  // The remote location to download from
  optional string workdir = 2 [default="pubmed/baseline"];
}

// The ClusterConfig defines the ray cluster connection param. Any cluster-specific deatuls will occur here.
message ClusterConfig {
  // Where to connect to cluster.
  optional string address = 1 [default="localhost"];
  optional int32 port = 2 [default=8786];
  // Fast scratch dir to use for intermediate storage.
  optional string local_scratch = 3 [default="/tmp"];
  optional string shared_scratch = 4;
  // Restarting cluster refreshes all code, but also clears stored datasets.
  optional bool restart = 5 [default=false];
  optional bool run_locally = 6 [default=false];
  optional bool clear_checkpoints = 7 [default=false];
  optional bool disable_checkpoints = 8 [default=false];
}

message TextParserConfig {
  optional string scispacy_version = 1;
  // May be a path to a bert model, or any of the transformer pretrained models.
  // Example: "./data/scibert" or "bert-base-uncased"
  optional string bert_model = 2 [default="bert-base-uncased"];
  // Discard sentences that are too long/short
  optional int32 min_sentence_len = 3 [default=10];
  optional int32 max_sentence_len = 4 [default=1000];
  // Path to stopwords. One word per line.
  optional string stopword_list = 5;
  // The BERT model will error out if given a too-long sequence.
  // Long sequences will be truncated.
  optional int32 max_sequence_length = 6 [default=500];
}

message NGramConfig {
  // When performing n-gram mining, how long should a potential n-gram be?
  // Set less than j to disable n-gram mining
  optional int32 max_ngram_length = 1 [default=3];
  // Number of times an n-gram must occur before its determined to be real
  optional int32 min_ngram_support = 2 [default=100];
  // Number of times an n-gram must occur in a single partition in order to
  // count.  This is an approximation factor, because otherwise we're going to
  // communicate a ton of bad ngrams.
  optional int32 min_ngram_support_per_partition = 3 [default=2];
}

message KnnConfig {
  optional int32 num_neighbors = 1 [default=100];
  optional int32 num_centroids = 2 [default=2048];
  optional int32 num_probes = 3 [default=16];
  optional int32 num_quantizers = 4 [default=96];
  optional int32 bits_per_quantizer = 5 [default=8];
  // The probability that a randomly selected record is included in the inital
  // training procedure.
  optional float training_probability = 6 [default=0.01];
}

message RedisConfig {
  optional string address = 1 [default="localhost"];
  optional int32 port = 2 [default=6379];
  optional int32 db_num = 3 [default=0];
  // Only used on construct
  optional bool clear=4 [default=false];
}

message LdaConfig {
  optional int32 num_topics = 1 [default=20];
  optional int32 random_seed = 2 [default=42];
  optional int32 iterations = 3 [default=50];
  // Remove any word that does not occur at least X times
  optional int32 min_support_count = 4 [default=2];
  // Remove any word that occurs in X proportion of docs.
  optional float max_support_fraction = 5 [default=0.1];
  // Take the top X words per-topic
  optional int32 truncate_size = 7 [default=250];
}

message MlConfig {
  optional int32 batch_size = 1 [default=32];
  optional bool disable_gpu = 2 [default=false];
  // only used for training
  optional int32 num_epochs = 3 [default=10];
  optional float validation_ratio = 4 [default=0.1];
  optional bool single_gpu = 5 [default=false];
}

message ConstructDebugConfig {
  optional bool enable = 1 [default=false];
  optional float document_sample_rate = 2 [default=0.1];
  optional int32 partition_subset_size = 3 [default=50];
}

message ShortestPathConfig {
  // Number of nodes to download at a time.
  optional int32 node_batch = 1 [default=10];
}

message PretrainedModelConfig {
  // When you add models to the construction process / ml module, add
  // optional params here to notify the construction process.
  optional string sentence_classifier_path = 1;
}

message MySqlConfig {
  optional string address = 1;
  optional string db = 2;
  optional string user = 3;
  optional string password = 4;
}

////////////////////////////////////////////////////////////////////////////////

// Config used to construct the network.
message ConstructConfig {
  // Details about the ray cluster
  optional ClusterConfig cluster = 1;
  // Details about the medline distribution to download.
  optional FtpSource ftp = 3;
  optional TextParserConfig parser = 4;
  optional KnnConfig sentence_knn = 5;
  // if set, sample our input by this rate.
  optional RedisConfig db = 6;
  optional MlConfig sys = 7;
  optional ConstructDebugConfig debug = 8;
  optional NGramConfig phrases = 9;
  // If set, we're going to stop the construction process once we checkpoint
  // this value. Used to help prepare data for the ML process.
  optional string stop_after_ckpt = 10;
  optional PretrainedModelConfig pretrained = 11;
}

// Config used to query the network.
message QueryConfig {
  optional string source = 1;
  optional string target = 2;
  optional RedisConfig db = 3;
  optional int32 max_sentences_per_path_elem = 4 [default=5000];
  optional LdaConfig topic_model = 5;
  optional ShortestPathConfig path = 6;
  // optional NGramConfig phrases = 7;
  // Where to store result proto
  optional string result_path = 8;
  optional bool override = 9 [default=false];
}

////////////////////////////////////////////////////////////////////////////////

message SentenceClassifierConfig {
  // Root to the scratch directory
  optional ClusterConfig cluster = 1;
  optional string shared_scratch = 2;
  optional MlConfig sys = 3;
  optional float test_set_ratio = 5 [default=0.2];
  optional float validation_set_ratio = 6 [default=0.1];
  optional bool force_retrain = 7 [default=false];

  // Path to custom data, used to specify benchmark data that might not be a
  // typical checkpoint. Note, the sentence data will still be loaded from the
  // typical shared_scratch. This just modifies the train/validation/test data.
  optional string custom_data_dir = 8;
}

message AbstractGeneratorConfig {
  optional ClusterConfig cluster = 1;
  optional TextParserConfig parser = 2;
  optional MlConfig sys = 3;
  // The following effect how often the second training sentence is modified.
  // This is the probability that the 2nd sentence is unchanged
  optional float unchanged_prob = 4 [default=0.1];
  // This is the probability that the whole 2nd sentence is dropped
  optional float full_mask_prob = 5 [default=0.2];
  // This is the per-token probability that a single word is dropped (provided
  // the above conditions have not happened)
  optional float mask_per_token_prob = 6 [default=0.2];
  optional bool use_horovod = 7 [default=false];
}
////////////////////////////////////////////////////////////////////////////////

message SemMedDBAddonConfig {
  optional MySqlConfig semmeddb = 1;
  optional RedisConfig pymolieredb = 2;

  // This is the edge weight between a sentence and its predicate Remember that
  // the baseline of 1 is the weight between two adjacent sentences. Also
  // remember that edge weights are a measure of "distance" as in larger =
  // weaker.
  optional float sentence_predicate_weight = 3 [default=0.75];

  // This is the edge weight between a umls term and a predicate
  optional float term_predicate_weight = 4 [default=0.75];
}
